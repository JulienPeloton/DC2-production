{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Tests of Object Catalog Access\n",
    "Owners: **Michael Wood-Vasey [@wmwv](https://github.com/LSSTDESC/DC2_Repo/issues/new?body=@wmwv)**  \n",
    "Last Run: **2018-07-31**\n",
    "\n",
    "Assess the performance of data manipulations of the Object catalogs using GCRCatalogs and Pandas.\n",
    "\n",
    "### Summary\n",
    "1. GCRCatalogs initializes+loads the full catalog in 330 seconds.\n",
    "2. Pandas loads the full catalog in 130 seconds.\n",
    "3. Using a trimmed file consistent only of the columns exposed through the DPDD is 10 times smaller than the full file.\n",
    "4. [Init+]Load times for both GCRCatalogs and Pandas are 10-20 times faster using the trim files.\n",
    "5. Once data are loaded, GCRCatalogs takes 1 second to compute the average color.  Pandas takes 2 milliseconds.\n",
    "6. Analyses with the HDF5 `format='table'` are 1-2 times slower than HDF5 `format='fixed'` files when there's no caching.\n",
    "7. When caching is allowed, using the HDF5 `format='table'` don't get cached and are 30 times slower than using HDF5 `format='fixed'` files.\n",
    "8. Using the GCR iterator is 30% faster when data are cached.\n",
    "9. A preliminary Dask analyses is conducted here, but a fuller development of Dask will be done in issues #237.\n",
    "\n",
    "### Discusion\n",
    "1. We should create trimed file versions for future releases.\n",
    "2. The `format='table'` does not work with GCR's caching.  This may be in the reader in GCRCatalogs, or it may be something more fundamental in how the caching is set up in GCR.\n",
    "3. Pandas creates the compressed representation of memory, mapping the flags to the bools that they are.  This leads to a factor of 10 reduction in the memory footprint of the Pandas object over the on-disk files, such that it easily fits in memory (8 GB).\n",
    "4. Dask may prove particularly useful once the Pandas data frames no longer fit in memory.  See Dask work (#237).\n",
    "\n",
    "### Original Charge\n",
    "1. Identify trivial, moderate, and worst-case use case examples.\n",
    "2. Measure performance on\n",
    "    1. single patch\n",
    "    2. a single tract\n",
    "    3. the full dataset\n",
    "3. Record data sizes of each of the above A, B, C\n",
    "4. Determine if performance considerations mean we should generate a static file that contains a restricted set in columns.\n",
    "5. Look into again using full tables functionality to write HDF5 files so that they can be read by column efficiently. This was previously not possible because of an error trying to write the thousands of columns in our full coadd catalogs. This is #158\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##to use user's gcr-catalogs\n",
    "#import sys\n",
    "#sys.path.insert(0, '../../gcr-catalogs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How fast is GCRCatalogs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GCRCatalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use the GCR reader outside of NERSC environment, you can override the `base_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "trim_config = config.copy()\n",
    "trim_config['filename_pattern'] = r'trim_merged_tract_\\d+\\.hdf5$'\n",
    "table_trim_config = config.copy()\n",
    "table_trim_config['filename_pattern'] = r'table_trim_merged_tract_\\d+\\.hdf5$'\n",
    "\n",
    "trim_onetract_config = config.copy()\n",
    "trim_onetract_config['filename_pattern'] = 'trim_merged_tract_4850\\.hdf5$'\n",
    "table_trim_onetract_config = config.copy()\n",
    "table_trim_onetract_config['filename_pattern'] = 'table_trim_merged_tract_4850\\.hdf5$'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time loading of GCRCatalogs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the GCR Catalog is, in principle, just the initialization of the catalog.  In practice the GCRCatalog reader does need to read through all of the metadata in the HDF5 files to figure out what's in there and available.  The onetract version is reading a 7.4 GB file that should fit in memory.  The full Run 1.1p is 78 GB, which does not fit in the average desktop memory.  This size could pontentially fit in the memory of various high-memory shared nodes.  This difference in size is conveniently roughly a factor of 10.  We should naively expect that operations will take 10x longer when all of the data fits in memory, and potentially 10-100x longer when the data do not.  The range is estimated across a variety of usage patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trim files are 1/10 of the size of the full files due to the removal of 90% of the columns.  The `load_catalog` doesn't load the data, but does need to open and touch each file to read the metadata.  This metadata reading step is only about 2 times faster for the trim files than for the full files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838 ms ± 34.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_onetract = GCRCatalogs.load_catalog('dc2_coadd_run1.1p_tract4850', config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 ms ± 13 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_onetract_trim = GCRCatalogs.load_catalog('dc2_coadd_run1.1p_tract4850', trim_onetract_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_onetract = GCRCatalogs.load_catalog('dc2_coadd_run1.1p_tract4850', config)\n",
    "gc_onetract_trim = GCRCatalogs.load_catalog('dc2_coadd_run1.1p_tract4850', trim_onetract_config)\n",
    "gc_onetract_table_trim = GCRCatalogs.load_catalog('dc2_coadd_run1.1p_tract4850', table_trim_onetract_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.4 s ± 213 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc = GCRCatalogs.load_catalog('dc2_coadd_run1.1p', config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.01 s ± 89 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_trim = GCRCatalogs.load_catalog('dc2_coadd_run1.1p', trim_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.7 s ± 168 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_table_trim = GCRCatalogs.load_catalog('dc2_coadd_run1.1p', table_trim_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note above that the table version of the trim catalogs takes the same amount of time as the full file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we actually run and save the objects for later use.\n",
    "# In the %%timeit runs above, the resulting bound names and objects are discarded.\n",
    "gc = GCRCatalogs.load_catalog('dc2_coadd_run1.1p', config)\n",
    "gc_trim = GCRCatalogs.load_catalog('dc2_coadd_run1.1p', trim_config)\n",
    "gc_table_trim = GCRCatalogs.load_catalog('dc2_coadd_run1.1p', table_trim_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time calculation using loaded GCRCatalogs objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "  * The trim catalog files are 10-30 faster to process than the full catalog files.\n",
    "  * The 'table' format trim catalog files take 1-2 as long to process as the trim catalog files.\n",
    "  * The full catalog files take 330 seconds to compute the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_color_slow(catalog):\n",
    "    \"\"\"Compute the mean g-r color of all objects in the 'catalog'.\n",
    "    \n",
    "    This is a trivial performance case.\n",
    "    This isn't particularly immediately interesting, but it's a simple arithmetic operation between two columns.\n",
    "    \"\"\"\n",
    "    average_gmr = (catalog['mag_g'] - catalog['mag_r']).mean()\n",
    "    return average_gmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_color_slow_native(catalog):\n",
    "    \"\"\"Compute the mean g-r color of all objects in the 'catalog' using native g_mag.\n",
    "    \n",
    "    This is a trivial performance case.\n",
    "    This isn't particularly immediately interesting, but it's a simple arithmetic operation between two columns.\n",
    "    \"\"\"\n",
    "    average_gmr = (catalog['g_mag'] - catalog['r_mag']).mean()\n",
    "    return average_gmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_color_faster(catalog):\n",
    "    \"\"\"Compute the mean g-r color of all objects in the 'catalog'.\n",
    "    \n",
    "    This is a trivial performance case.\n",
    "    This isn't particularly immediately interesting, but it's a simple arithmetic operation between two columns.\n",
    "    \"\"\"\n",
    "    data = catalog.get_quantities(['mag_g', 'mag_r'])\n",
    "    average_gmr = (data['mag_g'] - data['mag_r']).mean()\n",
    "    return average_gmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_color_faster_iter(catalog):\n",
    "    \"\"\"Compute the mean g-r color of all objects in the 'catalog' using iterator.\n",
    "    \n",
    "    This is a trivial performance case.\n",
    "    This isn't particularly immediately interesting, but it's a simple arithmetic operation between two columns.\n",
    "    \"\"\"\n",
    "    sum_gmr = count = 0\n",
    "    for data in catalog.get_quantities(['mag_g', 'mag_r'], return_iterator=True):\n",
    "        sum_gmr += (data['mag_g'] - data['mag_r']).sum()\n",
    "        count += len(data['mag_g'])\n",
    "    return sum_gmr / count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We below clear the memory cache with `GCRCatalogs` with `clear_cache()` method on the load object to reset for performance tests.  It's harder to control the underlying caching of the GPFS and kernel filesystem memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average color calculation is 18 times faster with the trim files for one tract.  It's only 2 times faster for the full set of files.\n",
    "\n",
    "There's no particular difference in elapsed time between the `compute_mean_slow`, `compute_mean_fast` and `compute_mean_fast_iter` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.9 s ± 1.44 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_onetract.clear_cache()\n",
    "compute_mean_color_slow(gc_onetract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.2 s ± 2.15 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_onetract.clear_cache()\n",
    "compute_mean_color_slow_native(gc_onetract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853 ms ± 53.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_onetract_trim.clear_cache()\n",
    "compute_mean_color_slow(gc_onetract_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853 ms ± 53.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_onetract_table_trim.clear_cache()\n",
    "compute_mean_color_slow(gc_onetract_table_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5min 33s ± 5.75 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc.clear_cache()\n",
    "compute_mean_color_slow(gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.9 s ± 1.85 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_onetract.clear_cache()\n",
    "compute_mean_color_faster(gc_onetract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.4 s ± 409 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_trim.clear_cache()\n",
    "compute_mean_color_faster(gc_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.54 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1min ± 45 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_table_trim.clear_cache()\n",
    "compute_mean_color_faster(gc_table_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5min 42s ± 26 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc.clear_cache()\n",
    "compute_mean_color_faster(gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.4 s ± 1.36 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_onetract.clear_cache()\n",
    "compute_mean_color_faster_iter(gc_onetract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3 s ± 1.19 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_trim.clear_cache()\n",
    "compute_mean_color_faster_iter(gc_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.3 s ± 2.04 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc_table_trim.clear_cache()\n",
    "compute_mean_color_faster_iter(gc_table_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5min 28s ± 8.33 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gc.clear_cache()\n",
    "compute_mean_color_faster_iter(gc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time subsequent access to other columns after caching\n",
    "\n",
    "Next we will look at the performance of GCRCatalogs after having read through the data once for some other column, and then computing the performance on reading another column.\n",
    "\n",
    "While the user does care about the first experience timing, they really care about repeated access time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give chance to fill cache\n",
    "_ = gc.get_quantities(['ra', 'dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781 ms ± 76 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "compute_mean_color_faster(gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541 ms ± 135 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "compute_mean_color_faster_iter(gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give chance to fill cache\n",
    "_ = gc_trim.get_quantities(['ra', 'dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366 ms ± 42.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "compute_mean_color_faster(gc_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238 ms ± 13 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "compute_mean_color_faster_iter(gc_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give chance to fill cache\n",
    "_ = gc_table_trim.get_quantities(['ra', 'dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.9 s ± 1.03 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "compute_mean_color_faster(gc_table_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.3 s ± 2.27 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "compute_mean_color_faster_iter(gc_table_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "compute_mean_color_faster_iter(gc_table_trim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How fast is Pandas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "tract = 4850\n",
    "\n",
    "datafile_pattern = 'merged_tract_{:d}.hdf5'\n",
    "datafile_pattern_trim = 'trim_' + datafile_pattern\n",
    "datafile_pattern_table_trim = 'table_trim_' + datafile_pattern\n",
    "\n",
    "datafile_basename = datafile_pattern.format(tract)\n",
    "datafile_basename_trim = datafile_pattern_trim.format(tract)\n",
    "datafile_basename_table_trim = datafile_pattern_table_trim.format(tract)\n",
    "\n",
    "base_dir = '/global/projecta/projectdirs/lsst/global/in2p3/Run1.1/object_catalog'\n",
    "\n",
    "datafile = os.path.join(base_dir, datafile_basename)\n",
    "datafile_trim = os.path.join(base_dir, datafile_basename_trim)\n",
    "datafile_table_trim = os.path.join(base_dir, datafile_basename_table_trim)\n",
    "\n",
    "key_prefix = 'coadd'\n",
    "nx, ny = 8, 8\n",
    "patches = ['%d%d' % (i, j) for i in range(nx) for j in range (ny)]  # Note '%d%d' instead of '%d,%d'\n",
    "patch = patches[0]\n",
    "key = '%s_%d_%s' % (key_prefix, tract, patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time loading of catalog using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading just one patch of the tract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.9 ms ± 834 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_onepatch = pd.read_hdf(datafile, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1 ms ± 411 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_onepatch_trim = pd.read_hdf(datafile_trim, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.3 ms ± 504 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_onepatch_table_trim = pd.read_hdf(datafile_table_trim, key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load all of the patches in the tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tract_into_pandas(datafile, tract, key_prefix='coadd'):\n",
    "    \"\"\"Load all of the patches in one tract into Pandas\n",
    "    \n",
    "    Returns None if no data was successfully loaded.\n",
    "    \"\"\"\n",
    "    nx, ny = 8, 8\n",
    "    patches = ['%d%d' % (i, j) for i in range(nx) for j in range (ny)]  # Note '%d%d' instead of '%d,%d'\n",
    "\n",
    "    dfs = []\n",
    "    for patch in patches:\n",
    "        key = '%s_%d_%s' % (key_prefix, tract, patch)\n",
    "        try:\n",
    "            df = pd.read_hdf(datafile, key=key)\n",
    "        except:\n",
    "            continue\n",
    "        dfs.append(df)\n",
    "\n",
    "    if dfs:\n",
    "        df = pd.concat(dfs, ignore_index=True)\n",
    "    else:\n",
    "        df = None\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.4 s ± 1.78 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_onetract = load_tract_into_pandas(datafile, tract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.61 s ± 24.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_onetract_trim = load_tract_into_pandas(datafile_trim, tract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.27 s ± 180 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_onetract_table_trim = load_tract_into_pandas(datafile_table_trim, tract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onetract = load_tract_into_pandas(datafile, tract)\n",
    "df_onetract_trim = load_tract_into_pandas(datafile_trim, tract)\n",
    "df_onetract_table_trim = load_tract_into_pandas(datafile_table_trim, tract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11 ms ± 42.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_onetract['g_mag'] - df_onetract['r_mag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.09 ms ± 97.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "(df_onetract['g_mag'] - df_onetract['r_mag']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.56 ms ± 30.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_onetract_trim['g_mag'] - df_onetract_trim['r_mag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.38 ms ± 74.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "(df_onetract_trim['g_mag'] - df_onetract_trim['r_mag']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332 µs ± 5.78 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_onetract_table_trim['g_mag'] - df_onetract_table_trim['r_mag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.45 ms ± 17 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "(df_onetract_table_trim['g_mag'] - df_onetract_table_trim['r_mag']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load all 20 tracts (many are only partially complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullpath_datafile_pattern = os.path.join(base_dir, datafile_pattern)\n",
    "fullpath_datafile_pattern_trim = os.path.join(base_dir, datafile_pattern_trim)\n",
    "fullpath_datafile_pattern_table_trim = os.path.join(base_dir, datafile_pattern_table_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_tracts_into_pandas(\n",
    "    datafile_pattern,\n",
    "    tracts=(5066, 5065, 5064, 5063, 5062,\n",
    "            4852, 4851, 4850, 4849, 4848,\n",
    "            4640, 4639, 4638, 4637, 4636,\n",
    "            4433, 4432, 4431, 4430, 4429),\n",
    "    verbose=False,\n",
    "    **kwargs):\n",
    "    dfs = []\n",
    "    for t in tracts:\n",
    "        datafile = datafile_pattern.format(t)\n",
    "        if verbose:\n",
    "            print(datafile)\n",
    "        df = load_tract_into_pandas(datafile, t, **kwargs)\n",
    "        if df is not None:\n",
    "            dfs.append(df)\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 13s ± 7.65 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df = load_all_tracts_into_pandas(fullpath_datafile_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.03 s ± 137 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_trim = load_all_tracts_into_pandas(fullpath_datafile_pattern_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.19 s ± 187 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_table_trim = load_all_tracts_into_pandas(fullpath_datafile_pattern_table_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_all_tracts_into_pandas(fullpath_datafile_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trim = load_all_tracts_into_pandas(fullpath_datafile_pattern_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_table_trim = load_all_tracts_into_pandas(fullpath_datafile_pattern_table_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332 µs ± 10.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df['g_mag'] - df['r_mag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.63 ms ± 50.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "(df['g_mag'] - df['r_mag']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607 µs ± 15.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_trim['g_mag'] - df_trim['r_mag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.72 ms ± 34.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "(df_trim['g_mag'] - df_trim['r_mag']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611 µs ± 6.48 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_table_trim['g_mag'] - df_table_trim['r_mag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.81 ms ± 74.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "(df_table_trim['g_mag'] - df_table_trim['r_mag']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "(df_table_trim['g_mag'] - df_table_trim['r_mag']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These calculation times are identical for the three different catalogs.  This is consistent with the logical need; each operation is reading two columns and subtracting them.\n",
    "\n",
    "Note that subtracting the arrays takes only hundreds of microseconds.  Aggregating the result takes 10 times longer, although we're still only a milliseconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we inspect the Pandas objects, we can see that one significant savings is that Pandas as explicitly loaded the flags as `bool`.  This immediately leads to a factor of 10 memory savings over the 80 GB of the HDF5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 719228 entries, 0 to 5023\n",
      "Columns: 2454 entries, base_Blendedness_abs_child_xx to z_slot_Shape_yy\n",
      "dtypes: bool(1177), float32(67), float64(1181), int32(21), int64(8)\n",
      "memory usage: 7.4 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 719228 entries, 0 to 5023\n",
      "Columns: 111 entries, i_base_PsfFlux_fluxSigma to z_base_SdssShape_xy\n",
      "dtypes: bool(22), float32(3), float64(84), int64(2)\n",
      "memory usage: 500.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_trim.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 719228 entries, 0 to 5023\n",
      "Columns: 111 entries, i_base_PsfFlux_fluxSigma to z_base_SdssShape_xy\n",
      "dtypes: bool(22), float32(3), float64(84), int64(2)\n",
      "memory usage: 500.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_table_trim.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So while it takes 240 seconds to load the full set of catalogs, the resulting Pandas object is only ~8 GB and so easily fits in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How fast is Dask?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section on Dask is very preliminary and will be improved upon in future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask as da\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(processes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract = 4850\n",
    "\n",
    "base_dir = '/global/projecta/projectdirs/lsst/global/in2p3/Run1.1/summary'\n",
    "\n",
    "datafile = os.path.join(base_dir, 'table_trim_merged_tract_%d.hdf5' % tract)\n",
    "datafile_pattern = os.path.join(base_dir, 'table_trim_merged_tract_*.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time loading of catalog using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_df = dd.read_hdf(datafile, key='coadd_*', mode='r')\n",
    "da_df_all = dd.read_hdf(datafile_pattern, key='coadd_*', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = np.mean(da_df['g_mag'] - da_df['r_mag'])\n",
    "df2_all = np.mean(da_df_all['g_mag'] - da_df_all['r_mag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time computation using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.91 s ± 87.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df2.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 3s ± 1.76 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df2_all.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the full DASK calculation takes 20 times longer than the onetract calculation for a data volume only 10-times larger.  We're potentially hitting memory limits, but there also might be some ineficiencies.\n",
    "\n",
    "DASK takes ~38 seconds to do the color average using the `table_trim_` file, while GCRCatalogs takes ~12 seconds using the `trim_` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv('OMP_NUM_THREADS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it matter if we're on Lustre (SCRATCH)\n",
    "\n",
    "No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/global/cscratch1/sd/wmwv/DC2/Run1.1p/summary'\n",
    "\n",
    "datafile_lustre = os.path.join(base_dir, 'table_trim_merged_tract_%d.hdf5' % tract)\n",
    "datafile_pattern_lustre = os.path.join(base_dir, 'table_trim_merged_tract_*.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_df_lustre = dd.read_hdf(datafile_lustre, key='coadd_*', mode='r')\n",
    "da_df_all_lustre = dd.read_hdf(datafile_pattern_lustre, key='coadd_*', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_lustre = np.mean(da_df_lustre['g_mag'] - da_df_lustre['r_mag'])\n",
    "df2_all_lustre = np.mean(da_df_all_lustre['g_mag'] - da_df_all_lustre['r_mag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.24 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "5.43 s ± 4.82 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df2_lustre.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 28s ± 12.5 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df2_all_lustre.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time on the Luster file system (2, 42) sec seems about the same as the GPFS (2, 50) sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'distributed': {'worker': {'memory': {'target': False, 'spill': False, 'pause': 0.8, 'terminate': 0.95}, 'multiprocessing-method': 'forkserver', 'use-file-locking': True, 'profile': {'interval': '10ms', 'cycle': '1000ms'}}, 'version': 2, 'scheduler': {'allowed-failures': 3, 'bandwidth': 100000000, 'default-data-size': 1000, 'transition-log-length': 100000, 'work-stealing': True, 'worker-ttl': None}, 'client': {'heartbeat': '5s'}, 'comm': {'compression': 'auto', 'default-scheme': 'tcp', 'socket-backlog': 2048, 'recent-messages-log-length': 0, 'timeouts': {'connect': '10s', 'tcp': '30s'}}, 'dashboard': {'link': 'http://{host}:{port}/status', 'export-tool': False}, 'admin': {'tick': {'interval': '20ms', 'limit': '3s'}, 'log-length': 10000, 'log-format': '%(name)s - %(levelname)s - %(message)s', 'pdb-on-err': False}}, 'jobqueue': {'slurm': {'cores': 64, 'memory': '128GB', 'processes': 2, 'queue': 'debug', 'walltime': '00:10:00', 'job-extra': ['-C haswell', '-L SCRATCH, cscratch1']}}, 'array': {'chunk-size': '128MiB', 'rechunk-threshold': 4}, 'scheduler': 'threads', 'shuffle': 'tasks'}\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "dask.config.set(scheduler='threads')\n",
    "print(dask.config.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.09 s ± 662 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df2_lustre.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it matter if we're on the burst buffer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-python",
   "language": "python",
   "name": "desc-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
