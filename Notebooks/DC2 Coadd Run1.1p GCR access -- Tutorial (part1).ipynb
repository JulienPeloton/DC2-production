{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC2 Coadd Run1.1p GCR access\n",
    "\n",
    "__Purpose__: This tutorial will illustrate the basics of accessing the merged coadd catalogs through the Generic Catalog Reader (GCR, https://github.com/yymao/generic-catalog-reader) as well as how to select useful samples of stars/galaxies from the DM outputs.\n",
    "\n",
    "\n",
    "Note: This notebook is intended to be run through the JupyterHub NERSC interface available here: https://jupyter-dev.nersc.gov. To setup your NERSC environment, please follow the instructions available here: https://confluence.slac.stanford.edu/display/LSSTDESC/Using+Jupyter-dev+at+NERSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the coadd catalog with the GCR\n",
    "\n",
    "The [GCRCatalogs](https://github.com/LSSTDESC/gcr-catalogs) package is a DESC project which aims at gathering in one convenient location various simulation/data catalogs made available to the collaboration.  \n",
    "In this section, we illustrate how to use this tool to access the coadd catalogs from DC2 Run1.1p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GCRCatalogs\n",
    "# Load the coadd catalog\n",
    "catalog = GCRCatalogs.load_catalog('dc2_coadd_run1.1p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A significant numbers of catalogs besides the DC2 coadd are already available, use `sorted(GCRCatalogs.get_available_catalogs(False))` to see a full list and visit the [DC2 Data Product](https://confluence.slac.stanford.edu/display/LSSTDESC/DC2+Data+Product+Overview) page to see all the DC2 related catalogs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DC2 Coadd catalog Schema\n",
    "\n",
    "\n",
    "To see the quantities available in the catalog, you can use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(catalog.list_all_quantities())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meaning of these fields is documented in the [SCHEMA.md](https://github.com/LSSTDESC/gcr-catalogs/blob/master/GCRCatalogs/SCHEMA.md#schema-for-dc2-coadd-catalogs) file of the `gcr-catalog` repository.  \n",
    "As explained in that link, the values exposed here are not the native quantities produced by the Data Management stack, but instead this schema strives to follow the standard nomenclature of the LSST Data Products Definition Document [DPDD](http://ls.st/dpdd).\n",
    "\n",
    "The DPDD is an effort made by the LSST project to standardize the format of the official Data Release Products (DRP). While the native outputs of the DM stack are succeptible to change, the DPDD will be more stable. An early adoption of these conventions by the DESC will save time and energy down the road.\n",
    "\n",
    "This being said, not all use-cases and relevant quantities are covered by these conventions yet, so the GCR preserves access to the underlying native DM stack fieds, all 2046 of which can be listed using:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(catalog.list_all_native_quantities())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the catalog includes:\n",
    "\n",
    "* Positions\n",
    "* Fluxes and magnitudes (PSF and CModel)\n",
    "* Shapes (using GalSim's HSM)\n",
    "* Quality flags: e.g, does the source have any interpolated pixels? Has any of the measurement algorithms returned an error?\n",
    "* Other useful quantities: `blendedness`, measure of how flux is affected by neighbors: (1 - flux.child/flux.parent) (see 4.9.11 of 1705.06766); `extendedness`, classifies sources in extended and psf-like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the data\n",
    "\n",
    "While run1.1p is still of manageable size, full DC2 will be much larger, accessing the whole data can be challenging. In order to access the data efficiently, it is important to understand how it is physically stored and how to access it, one piece at the time. \n",
    "\n",
    "\n",
    "The coadds produced by the DM stack are structured in terms of large `tracts` and smaller `patches`, illustrated here for DC2:\n",
    "<img src=\"assets/dc2_skymap.png\">\n",
    "Here the tracts have large blue numbers, and the patches are denoted with an `(x,y)` format. For DC2, each tract has 8x8 patches.\n",
    "\n",
    "The GCR coadd catalog preserves this structure of the data so that any particular quantity can be accessed on a tract/patch bases. The tracts available in the catalog can be listed using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query all available tracts and patches, only displays the first 5\n",
    "catalog.available_tracts_and_patches[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access a particular part of the data, the GCR provides the following `native_filters` mechanism:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the ra,dec coordinates of all sources within tract number 4430\n",
    "data = catalog.get_quantities(['ra', 'dec'], native_filters=[(lambda x: x==4430, 'tract')])\n",
    "\n",
    "# Plot a 2d histogram of sources\n",
    "figure(figsize=(10,7))\n",
    "hist2d(data['ra'], data['dec'],100); gca().set_aspect('equal'); colorbar()\n",
    "xlabel('RA [deg]');\n",
    "ylabel('dec [deg]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data returned by the GCR is structured as a native Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it can also easily be converted into a Pandas DataFrame, if you are so inclined ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "pdata = pandas.DataFrame(data)\n",
    "pdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple test, you can show the advantage of loading one tract at a time compared to the entire catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time data = catalog.get_quantities(['ra', 'dec'], native_filters=[(lambda x: x==4431, 'tract')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time data = catalog.get_quantities(['ra', 'dec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make accessing chunks of data convenient to the user, the `catalog.get_quantities` also provides the option to return an iterator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all the patches of a given tract using an iterator\n",
    "for d in catalog.get_quantities(['ra', 'dec'],\n",
    "                                native_filters=[(lambda x: x==4850, 'tract')],\n",
    "                                return_iterator=True):\n",
    "    # Here we only handle a small amount of data at a time\n",
    "    plt.scatter(d['ra'], d['dec'], s=2);\n",
    "    \n",
    "plt.xlabel('RA');\n",
    "plt.ylabel('Dec');\n",
    "plt.title('Tract 4850');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying filters and cuts\n",
    "\n",
    "In order to avoid returning unecessary data, the GCR has a functionality to filter out entries as it reads the files. Note that this is different from the `native_filters` discussed above, which avoids reading part of the data altogether.\n",
    "\n",
    "Defining these filters requires the `GCRQuery` module of the GCR package and can then be applied during the call to `get_quantities`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GCR import GCRQuery\n",
    "\n",
    "# Simple cut to remove unreliable detections\n",
    "# More cuts can be added, as a logical AND, by appending GCRQuerys to this list\n",
    "simple_cuts = [\n",
    "    GCRQuery('clean'), # The source has no flagged pixels (interpolated, saturated, edge, clipped...) \n",
    "                       # and was not skipped by the deblender\n",
    "]\n",
    "\n",
    "# Loads the data after cut\n",
    "data_cut = catalog.get_quantities(['ra', 'dec'], \n",
    "                              filters = simple_cuts, \n",
    "                              native_filters=[(lambda x: x==4849, 'tract')])\n",
    "\n",
    "# Loads data without cuts\n",
    "data_full = catalog.get_quantities(['ra', 'dec'], \n",
    "                              native_filters=[(lambda x: x==4849, 'tract')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a 2d histogram of sources\n",
    "figure(figsize=(15,7))\n",
    "subplot(121)\n",
    "hist2d(data_full['ra'], data_full['dec'],256); gca().set_aspect('equal'); \n",
    "xlabel('RA [deg]');\n",
    "ylabel('dec [deg]');\n",
    "title('Full sample')\n",
    "colorbar()\n",
    "\n",
    "subplot(122)\n",
    "hist2d(data_cut['ra'], data_cut['dec'],256); gca().set_aspect('equal');\n",
    "xlabel('RA [deg]');\n",
    "ylabel('dec [deg]');\n",
    "title('Clean objects');\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==TODO==: Check this plot I'm a bit confused, I was expecting to see some cosmic rays and stars.... This example turned to be very underwhelming, maybe we should just go directly for star/galaxy separation. JS: I like the example even if the simulated image is boring (Also the number of exposures for a LSST coadd is much larger than the ones for HSC so I guess that will lower the impact of CRs and other defects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_hsc = GCRCatalogs.load_catalog('hsc-pdr1-xmm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the data after cut\n",
    "data_cut = cat_hsc.get_quantities(['ra', 'dec'], \n",
    "                              filters = simple_cuts)\n",
    "\n",
    "# Loads data without cuts\n",
    "data_full = cat_hsc.get_quantities(['ra', 'dec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(15,7))\n",
    "subplot(121)\n",
    "hist2d(data_full['ra'], data_full['dec'],256); gca().set_aspect('equal'); \n",
    "xlabel('RA [deg]');\n",
    "ylabel('dec [deg]');\n",
    "title('Full sample')\n",
    "\n",
    "subplot(122)\n",
    "hist2d(data_cut['ra'], data_cut['dec'],256); gca().set_aspect('equal');\n",
    "xlabel('RA [deg]');\n",
    "ylabel('dec [deg]');\n",
    "title('Clean objects');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of filtering: Star/galaxy separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we have `extendedness == base_ClassificationExtendedness_value` as a tool for star/galaxy classification. An object is considered extended if the the difference between the `PSF` magnitude and the `CModel` magnitude is beyond certain threshold (0.0164). To know more about this see [Bosch et al. 2017](https://arxiv.org/pdf/1705.06766.pdf) section 4.9.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_cuts = [\n",
    "    GCRQuery('clean'), # The source has no flagged pixels (interpolated, saturated, edge, clipped...) \n",
    "                       # and was not skipped by the deblender\n",
    "    GCRQuery('extendedness==0'),\n",
    "]\n",
    "\n",
    "quantities = ['mag_g_cModel', 'mag_r_cModel', 'mag_i_cModel']\n",
    "\n",
    "d = catalog.get_quantities(quantities, \n",
    "                           filters=star_cuts, \n",
    "                           native_filters=[(lambda x: x==4849, 'tract')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, we are selected what we think are stars. Let's take a look at the colors of these objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(d['mag_g_cModel']-d['mag_r_cModel'],\n",
    "           d['mag_r_cModel']-d['mag_i_cModel'], \n",
    "           bins=100,range=[(-1,2),(-1,2)]);\n",
    "plt.xlabel('$g-r$')\n",
    "plt.ylabel('$r-i$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check what the input stars colors look like [here](https://github.com/LSSTDESC/DC2_Repo/blob/u/yymao/cmu_tutorials/Notebooks/DC2%20Coadd%20Run1.1p%20direct%20access%20--%20color-color%20stellar%20locus.ipynb)\n",
    "\n",
    "==TODO==: Whenever we have the definitive path to the notebooks, update link!\n",
    "\n",
    "Q: What else can you do to improve the star selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a useful sample of galaxies: lensing cuts from HSC DR1\n",
    "\n",
    "In this section, we will build step by step a sample of galaxies from the DC2 run1.1p coadd catalog, and compare it to an equivalent sample built from the HSC DR1 catalog.\n",
    "\n",
    "### Sample selection\n",
    "\n",
    "We will start from a set of basic sanity cuts that will select extended objects and reject problematic sources, including those for which shape measurement has failed.\n",
    "\n",
    "One subtelty is that shape measurement is only run for the *reference band*, which is most of the time the i-band, but not always, we will further restrict the sample to objects for which we have i-band shapes using the `merge_measurement_i` flag.\n",
    "\n",
    "==TODO==: Do we need to explain this further? JS: I'd say no, but let's say what our alpha testers think :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cuts = [\n",
    "    GCRQuery('extendedness > 0'),    # Extended objects\n",
    "    GCRQuery('merge_measurement_i'), # Select objects for which the reference is the i-band\n",
    "    \n",
    "    GCRQuery('clean'), # The source has no flagged pixels (interpolated, saturated, edge, clipped...) \n",
    "                       # and was not skipped by the deblender\n",
    "    ~GCRQuery('xy_flag'),                                       # Flag for bad centroid measurement\n",
    "    ~GCRQuery('ext_shapeHSM_HsmShapeRegauss_flag'),             # Error code returned by shape measurement code\n",
    "    ~GCRQuery((np.isnan, 'ext_shapeHSM_HsmShapeRegauss_sigma')) # Shape measurement uncertainty should not be NaN\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to these basic cuts, we will want to apply a set of cuts based on object properties, to ensure we are selecting well resolved and well measured galaxies. One of these properties is the measured total distortion, which is not directly defined in the schema, but can be derived from the measured $e1$, $e2$ distortion components according to $|e| = \\sqrt{e_1^2 + e_2^2 }$\n",
    "\n",
    "The GCR provides a convenience function, `add_quantity_modifier`, to add this quantity to the schema on the fly, so that we can use it afterwards to build our cuts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the new derived column \n",
    "catalog.add_quantity_modifier('shape_hsm_regauss_etot', \n",
    "                              (np.hypot, 'ext_shapeHSM_HsmShapeRegauss_e1', 'ext_shapeHSM_HsmShapeRegauss_e2'), \n",
    "                              overwrite=True)\n",
    "\n",
    "# Define lensing cuts on galaxy properties \n",
    "properties_cuts = [\n",
    "    GCRQuery('snr_i_cModel > 10'),                              # SNR > 10\n",
    "    GCRQuery('mag_i_cModel < 24.5'),                            # cModel imag brighter than 24.5\n",
    "    GCRQuery('ext_shapeHSM_HsmShapeRegauss_resolution >= 0.3'), # Sufficiently resolved galaxies compared to PSF\n",
    "    GCRQuery('shape_hsm_regauss_etot < 2'),                     # Total distortion in reasonable range\n",
    "    GCRQuery('ext_shapeHSM_HsmShapeRegauss_sigma <= 0.4')       # Shape measurement errors reasonable\n",
    "]\n",
    "\n",
    "# We can now extract our lensing sample \n",
    "quantities = ['mag_i_cModel', 'snr_i_cModel', 'shape_hsm_regauss_etot', 'ext_shapeHSM_HsmShapeRegauss_resolution']\n",
    "data = catalog.get_quantities(quantities, \n",
    "                           filters=basic_cuts + properties_cuts, \n",
    "                           native_filters=[(lambda x: x==4849, 'tract')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,10))\n",
    "subplot(221)\n",
    "hist(data['ext_shapeHSM_HsmShapeRegauss_resolution'], 100, range=[0,1],normed=True);\n",
    "xlabel('i-band resolution')\n",
    "xlim()\n",
    "subplot(222)\n",
    "hist(data['snr_i_cModel'], 100, range=[0,100],normed=True)\n",
    "xlabel('i-band cmodel S/N')\n",
    "subplot(223)\n",
    "hist(data['mag_i_cModel'], 100, range=[20,25],normed=True);\n",
    "xlabel('i-band cmodel mag')\n",
    "subplot(224)\n",
    "hist(data['shape_hsm_regauss_etot'],100,normed=True);\n",
    "xlabel('Ellipticity magniture |e|');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare this plot to Fig 12. in [Mandelbaum et al. 2017](https://arxiv.org/pdf/1705.06745.pdf):\n",
    "<img src=\"assets/fig12_mandelbaum2017.png\">\n",
    "\n",
    "A quick visual comparison will highlight two things:\n",
    "\n",
    "  - We are missing a lot of galaxies between 23 and 24.5 mag\n",
    "  - We have a bump near resolution of 1\n",
    "\n",
    "We are going to investigate to understand these differences below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the depth of the survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One obvious reason why we would be missing some faint galaxies is if DC2 run1.1p is shallower than HSC. We will test this here by measuring the depths of both run 1.1p and the HSC DR1 XMM field. More generally, it is also a concern for most science analysis to have spatially uniform sampled data, which can be checked by looking at the depth of the sample.  \n",
    "\n",
    "There are several ways to do this, in this case, we are going to check what's the magnitude which has a median SNR closest to 10, the SNR cut of our lensing sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "from cic import binned_statistic  # Import and efficient alternative to binned_statistic_2d, defined in cic.py\n",
    "\n",
    "def depth_map_snr (ra, dec, mags, snr,snr_threshold=10,nside=2048):\n",
    "    \"\"\"\n",
    "    Constructs a depth map on a healpix grid for a given SNR threshold.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ra, dec: Array of coordinates on the sky (in deg.)\n",
    "    mags, snr : measured magnitude and snr for the sample\n",
    "    snr_threshold: SNR\n",
    "    \"\"\"\n",
    "    # Remove potentially problematic entries\n",
    "    good = np.logical_or(np.logical_not(np.isnan(ra)),np.logical_not(np.isnan(dec)))\n",
    "    # Create array of healpix pixel indices corresponding to coordinates \n",
    "    pix_nums = hp.ang2pix(nside,np.pi/2.-dec[good]*np.pi/180,ra[good]*np.pi/180)\n",
    "    \n",
    "    # Create output map\n",
    "    map_out = np.zeros(12*nside**2)\n",
    "    \n",
    "    # Bins in magnitudes\n",
    "    bin_centers = np.linspace(22+6/30.,28-6/30.,30.)\n",
    "    \n",
    "    # For each healpix pixel\n",
    "    for px in np.unique(pix_nums):\n",
    "        # Select all objects within this pixel\n",
    "        mask = px==pix_nums\n",
    "        if np.count_nonzero(mask)>0:\n",
    "            # Compute median snr in bins of magnitude\n",
    "            median_snr = binned_statistic(mags[mask],snr[mask],np.nanmedian,nbins=30,range=(22,28))\n",
    "            mask2 = np.isnan(median_snr)==False\n",
    "            # Find magnitude corresponding to snr threshold\n",
    "            if np.count_nonzero(mask2)>0:\n",
    "                depth = bin_centers[mask2][np.argmin(np.fabs(median_snr[mask2] - snr_threshold))]\n",
    "                map_out[px]=depth\n",
    "            else:\n",
    "                map_out[px]=0\n",
    "        else:\n",
    "            map_out[px]=0.\n",
    "    return map_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantities = ['ra', 'dec', 'mag_i_cModel', 'snr_i_cModel', 'ext_shapeHSM_HsmShapeRegauss_resolution']\n",
    "\n",
    "# Data from DC2 run1.1p\n",
    "data_dc2 = catalog.get_quantities(quantities, \n",
    "                                  filters=basic_cuts, # Note the only apply the basic_cuts\n",
    "                                  native_filters=[(lambda x: x==4849, 'tract')])\n",
    "\n",
    "# Data from HSC DR1 XMM field \n",
    "cat_hsc = GCRCatalogs.load_catalog('hsc-pdr1-xmm')\n",
    "data_hsc = cat_hsc.get_quantities(quantities,\n",
    "                                  filters=basic_cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute i-band depth maps for both surveys\n",
    "m10map_dc2 = depth_map_snr(data_dc2['ra'],data_dc2['dec'],data_dc2['mag_i_cModel'], data_dc2['snr_i_cModel'])\n",
    "m10map_hsc = depth_map_snr(data_hsc['ra'],data_hsc['dec'],data_hsc['mag_i_cModel'], data_hsc['snr_i_cModel'])\n",
    "\n",
    "# Printing the median depth\n",
    "print(\"Run1.1p median i-band 10-sigma depth \", median(m10map_dc2[m10map_dc2 > 0]))\n",
    "print(\"HSC XMM median i-band 10-sigma depth \", median(m10map_hsc[m10map_hsc > 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we see the difference between the two samples, HSC is much deeper. This is partly due to the fact that run1.1p was interrupted mid-run so it doesn't reach the full depth of DC2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visually compare the 2 depth maps\n",
    "hp.gnomview(m10map_dc2,rot=(data_dc2['ra'].mean(), data_dc2['dec'].mean()), title='Run 1.1 Depth', reso=0.5,unit='10-$\\sigma$ i-band depth',min=22, max=27.)\n",
    "hp.gnomview(m10map_hsc,rot=(data_hsc['ra'].mean(), data_hsc['dec'].mean()), title='HSC DR1 XMM Depth', reso=0.5,unit='10-$\\sigma$ i-band depth',min=22, max=27.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of blendedness\n",
    " \n",
    "The second discrepancy between our sample and the Mandelbaum et al. plot is an excess of galaxies appearing very well resolved compared to the PSF (resolution > 0.9). To understand this difference, we are going to select a few of these objects and extract postage stamps from the DM stack for visual inspection.\n",
    "\n",
    "We begin by selecting galaxies in our lensing sample which are near perfectly resolved by adding a cut on resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cut = basic_cuts + properties_cuts + [GCRQuery('ext_shapeHSM_HsmShapeRegauss_resolution >= 0.98')]\n",
    "\n",
    "data = catalog.get_quantities(['ra', 'dec', 'mag_i_cModel', 'ext_shapeHSM_HsmShapeRegauss_resolution'], \n",
    "                              filters=sample_cut,\n",
    "                              native_filters=[(lambda x: x==4849, 'tract')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract a few postage stamps at these coordinates, to do so we will reuse some of the code from the [DC2 Postage Stamps tutorial](/DC2%20Postage%20Stamps.ipynb). Please have a look a this tutorial to understand the function we will be using here, but in a nustshell we are going to query the DM data Butler to retrieve cutouts of the Deep Coadd exposures of these objects in the i-band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.daf.persistence as dafPersist\n",
    "import lsst.afw.geom as afwGeom\n",
    "import lsst.afw.coord as afwCoord\n",
    "import lsst.afw.image as afwImage\n",
    "import lsst.afw.display as afwDisplay\n",
    "\n",
    "from astropy.table import Table\n",
    "from astropy.visualization import ZScaleInterval\n",
    "\n",
    "# Please check the DC2 Postage Stamps tutorial for all the details of how this works\n",
    "def cutout_coadd_ra_dec(butler, ra, dec, filt='i', datasetType='deepCoadd', \n",
    "                                  skymap=None, cutoutSideLength=50, **kwargs):\n",
    "    \"\"\"Produce a cutout from a coadd at the given ra,dec coordinates\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    --\n",
    "    butler - lsst.daf.persistence.Butler of the data repository\n",
    "    ra, dec - coordinates of the center of the cutout (in degrees).\n",
    "    filter - Filter of the image to load\n",
    "    datasetType - 'deepCoadd'  Which type of coadd to load.  Doesn't support 'calexp'\n",
    "    \n",
    "    skymap - [optional] Pass in to avoid the Butler read.  Useful if you have lots of them.\n",
    "    cutoutSideLength - [optional] Side of the cutout region in pixels.\n",
    "    \n",
    "    Returns\n",
    "    --\n",
    "    MaskedImage\n",
    "    \"\"\"\n",
    "    # Create a lsst.afw.geom.SpherePoint coordinates object\n",
    "    radec = afwGeom.SpherePoint(ra, dec, afwGeom.degrees)\n",
    "    cutoutSize = afwGeom.ExtentI(cutoutSideLength, cutoutSideLength)\n",
    "\n",
    "    if skymap is None:\n",
    "        skymap = butler.get(\"deepCoadd_skyMap\")\n",
    "    \n",
    "    # Retrieves the tract, patch info for these coordinates from the skymap\n",
    "    tractInfo = skymap.findTract(radec)\n",
    "    patchInfo = tractInfo.findPatch(radec)\n",
    "    \n",
    "    # Get pixel coordinates on the tract\n",
    "    xy = afwGeom.PointI(tractInfo.getWcs().skyToPixel(radec))\n",
    "    bbox = afwGeom.BoxI(xy - cutoutSize//2, cutoutSize)\n",
    "\n",
    "    coaddId = {'tract': tractInfo.getId(), 'patch': \"%d,%d\" % patchInfo.getIndex(), 'filter': filt}\n",
    "    \n",
    "    cutout_image = butler.get(datasetType+'_sub', bbox=bbox, immediate=True, dataId=coaddId)\n",
    "    \n",
    "    return cutout_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this tool to extract cutouts in hand, let's have a look at a few examples in our sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the data butler for the run 1.1p data repository\n",
    "repo = '/global/projecta/projectdirs/lsst/global/in2p3/Run1.1/output'\n",
    "butler = dafPersist.Butler(repo)\n",
    "\n",
    "figure(figsize=(15,15));\n",
    "for i in range(16):\n",
    "    subplot(4,4,i+1)\n",
    "\n",
    "    # Extract the cutout using the data butler\n",
    "    cutout_image = cutout_coadd_ra_dec(butler, data['ra'][i], data['dec'][i]);\n",
    "    \n",
    "    # Plot the postage stamp on the same scales, with some arcsinh range compression \n",
    "    imshow(arcsinh(cutout_image.image.array), vmax=4, cmap='binary');\n",
    "    \n",
    "    # Let's add a crosshair to guide the eye\n",
    "    axhline(25, color='k',alpha=0.5)\n",
    "    axvline(25, color='k',alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, one thing may jump to eye, these objects are supposed to be large, extremely well resolved, yet they often look fairly small... but they have a lot of sometimes very bright neighbours. This is very suspicious and may indicate a problem with the DM deblender.\n",
    "\n",
    "Looking at the [SCHEMA.md](https://github.com/LSSTDESC/gcr-catalogs/blob/master/GCRCatalogs/SCHEMA.md#schema-for-dc2-coadd-catalogs) one may notice a field named `blendedness`. This is a metric produced by the DM stack defined  for deblended objects and \"measures the fraction of the total flux in the neighborhood of a source that belongs to its neighbors\" [(Bosch et. 2017)](https://arxiv.org/pdf/1705.06766.pdf).\n",
    "\n",
    "Let's have a look at the `blendedness` values of the examples in our sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = catalog.get_quantities(['blendedness'], \n",
    "                              filters=sample_cut,\n",
    "                              native_filters=[(lambda x: x==4849, 'tract')])\n",
    "\n",
    "data['blendedness'][0:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one would expect, they all have a large values, close to 1, indicating that these objects belong to very blended neighborhoods. Because the deblender seems to be failing for these objects, we can use this metric to try to exclude them from our sample. \n",
    "\n",
    "As a matter of fact, this is what was done in the (Mandelbaum et al., 2017) paper where an additional cut on blendedness was introduced to guard against deblender failures. \n",
    "\n",
    "Let's try to rebuild our sample following the same approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_cuts = [\n",
    "    GCRQuery('snr_i_cModel > 10'),                              # SNR > 10\n",
    "    GCRQuery('mag_i_cModel < 24.5'),                            # cModel imag brighter than 24.5\n",
    "    GCRQuery('ext_shapeHSM_HsmShapeRegauss_resolution >= 0.3'), # Sufficiently resolved galaxies compared to PSF\n",
    "    GCRQuery('shape_hsm_regauss_etot < 2'),                     # Total distortion in reasonable range\n",
    "    GCRQuery('ext_shapeHSM_HsmShapeRegauss_sigma <= 0.4'),      # Shape measurement errors reasonable\n",
    "    # New cut on blendedness:\n",
    "    GCRQuery('blendedness < 10**(-0.375)')                      # Avoid spurious detections and those contaminated by blends\n",
    "]\n",
    "\n",
    "quantities = ['mag_i_cModel', 'snr_i_cModel', 'shape_hsm_regauss_etot', 'ext_shapeHSM_HsmShapeRegauss_resolution']\n",
    "data = catalog.get_quantities(quantities, \n",
    "                           filters=basic_cuts + properties_cuts, \n",
    "                           native_filters=[(lambda x: x==4849, 'tract')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,10))\n",
    "subplot(221)\n",
    "hist(data['ext_shapeHSM_HsmShapeRegauss_resolution'], 100, range=[0,1],normed=True);\n",
    "xlabel('i-band resolution')\n",
    "xlim()\n",
    "subplot(222)\n",
    "hist(data['snr_i_cModel'], 100, range=[0,100],normed=True)\n",
    "xlabel('i-band cmodel S/N')\n",
    "subplot(223)\n",
    "hist(data['mag_i_cModel'], 100, range=[20,25],normed=True);\n",
    "xlabel('i-band cmodel mag')\n",
    "subplot(224)\n",
    "hist(data['shape_hsm_regauss_etot'],100,normed=True);\n",
    "xlabel('Ellipticity magniture |e|');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\o/ The excess of high resolution objects has disappeared, mystery solved!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Galaxy counts-in-cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blending affects the accuracy of centroid and flux measurements. It can potentially generate a systematic effect in different measurements (for example 2-point statistics). \n",
    "\n",
    "The stack, returns a very useful value to check (partially) for the presence of these kind of systematics, which is the `blendedness` parameter (more details on Section 4.9.11 of [Bosch et al. 2017](https://arxiv.org/pdf/1705.06766.pdf)\n",
    "\n",
    "* Q: Why partially?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very simple tool to measure the different statistical moments of galaxies is Counts-in-cells (CiC) [Peebles et al. 1980](https://press.princeton.edu/titles/724.html). Here, we are going to use a simplified version of CiC to check the possible systematic effects due to differences in the `blendedness` measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what's CiC?\n",
    "\n",
    "1) Count the number of galaxies in a cell of a given scale.\n",
    "\n",
    "2) Measure the density contrast distribution and its moments.\n",
    "\n",
    "3) Change the scale and repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cic import cic_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import healpy as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use almost the same cuts as in the WL sample\n",
    "tract_number = 4849\n",
    "cic_cuts_nb = [\n",
    "    ~GCRQuery((np.isnan, 'mag_i_cModel')), # (from this and below) remove nan entries\n",
    "    ~GCRQuery((np.isnan, 'ext_shapeHSM_HsmShapeRegauss_resolution')),\n",
    "    ~GCRQuery((np.isnan, 'ext_shapeHSM_HsmShapeRegauss_e1')),\n",
    "    ~GCRQuery((np.isnan, 'ext_shapeHSM_HsmShapeRegauss_e2')),\n",
    "    GCRQuery('good'), \n",
    "    GCRQuery('snr_i_cModel >= 10'), # (from this and below) cut on object properties\n",
    "    GCRQuery('ext_shapeHSM_HsmShapeRegauss_sigma <= 0.4'),\n",
    "    GCRQuery('blendedness < 10**(-0.375)'),\n",
    "]\n",
    "\n",
    "cic_cuts_b = [\n",
    "    ~GCRQuery((np.isnan, 'mag_i_cModel')), # (from this and below) remove nan entries\n",
    "    ~GCRQuery((np.isnan, 'ext_shapeHSM_HsmShapeRegauss_resolution')),\n",
    "    ~GCRQuery((np.isnan, 'ext_shapeHSM_HsmShapeRegauss_e1')),\n",
    "    ~GCRQuery((np.isnan, 'ext_shapeHSM_HsmShapeRegauss_e2')),\n",
    "    GCRQuery('good'), \n",
    "    GCRQuery('snr_i_cModel >= 10'), # (from this and below) cut on object properties\n",
    "    GCRQuery('ext_shapeHSM_HsmShapeRegauss_sigma <= 0.4'),\n",
    "    GCRQuery('blendedness > 10**(-0.375)'),\n",
    "]\n",
    "\n",
    "quantities = ['ra','dec']\n",
    "d_nb = catalog.get_quantities(quantities, \n",
    "                           filters=cic_cuts_nb, \n",
    "                           native_filters=[(lambda x: x==tract_number, 'tract')])\n",
    "d_b = catalog.get_quantities(quantities, \n",
    "                           filters=cic_cuts_b, \n",
    "                           native_filters=[(lambda x: x==tract_number, 'tract')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(m5map)\n",
    "mask[m5map>23.0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.gnomview(mask,rot=(data['ra'].mean(), data['dec'].mean()), title='Run 1.1 Depth', reso=0.5,unit='10-$\\sigma$ i-band depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_b, sigma_err_b, skw_b, skw_err_b, kurtosis_b, kurtosis_err_b, pixel_scale = cic_analysis(d_b, mask, nboot=100)\n",
    "sigma_nb, sigma_err_nb, skw_nb, skw_err_nb, kurtosis_nb, kurtosis_err_nb, _  = cic_analysis(d_nb, mask, nboot=100)\n",
    "#TODO: Include CiC with shapes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,3,figsize=(16,4))\n",
    "ax[0].errorbar(pixel_scale, sigma_b, sigma_err_b, fmt='o', linestyle='none', label='High blendedness')\n",
    "ax[0].errorbar(pixel_scale, sigma_nb, sigma_err_nb, fmt='x', linestyle='none', label='Low blendedness')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel('Pixel scale [deg]')\n",
    "ax[0].set_ylabel(r'$\\sigma$')\n",
    "ax[1].errorbar(pixel_scale, skw_b, skw_err_b, fmt='o', linestyle='none', label='High blendedness')\n",
    "ax[1].errorbar(pixel_scale, skw_nb, skw_err_nb, fmt='x', linestyle='none', label='Low blendedness')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel('Pixel scale [deg]')\n",
    "ax[1].set_ylabel(r'$S_{3}$')\n",
    "ax[2].errorbar(pixel_scale, kurtosis_b, kurtosis_err_b, fmt='o', linestyle='none', label='High blendedness')\n",
    "ax[2].errorbar(pixel_scale, kurtosis_nb, kurtosis_err_nb, fmt='x', linestyle='none', label='Low blendedness')\n",
    "ax[2].legend()\n",
    "ax[2].set_xlabel('Pixel scale [deg]')\n",
    "ax[2].set_ylabel(r'$S_{4}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's definitely something going on with the high blendedness sources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Check if PSF residuals are within requirements\n",
    "\n",
    "- First explain how the DM stack models stars and PSF\n",
    "- How to select a sample of good looking stars\n",
    "- compute rho statistics in stile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = GCRCatalogs.load_catalog('dc2_coadd_run1.1p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: A few words about PSF modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds modifiers to compute stars size and ellipticity\n",
    "g1_modif = lambda ixx,iyy,ixy: (ixx-iyy)/(ixx+iyy)\n",
    "g2_modif = lambda ixx,iyy,ixy:  2.*ixy/(ixx+iyy)\n",
    "sigma_modif = lambda ixx,iyy,ixy: (ixx*iyy - ixy**2)**0.25\n",
    "\n",
    "catalog.add_modifier_on_derived_quantities('g1', g1_modif, 'Ixx', 'Iyy', 'Ixy')\n",
    "catalog.add_modifier_on_derived_quantities('g2', g2_modif, 'Ixx', 'Iyy', 'Ixy')\n",
    "catalog.add_modifier_on_derived_quantities('sigma', sigma_modif, 'Ixx', 'Iyy', 'Ixy')\n",
    "\n",
    "catalog.add_modifier_on_derived_quantities('psf_g1', g1_modif, 'IxxPSF', 'IyyPSF', 'IxyPSF')\n",
    "catalog.add_modifier_on_derived_quantities('psf_g2', g2_modif, 'IxxPSF', 'IyyPSF', 'IxyPSF')\n",
    "catalog.add_modifier_on_derived_quantities('psf_sigma', sigma_modif, 'IxxPSF', 'IyyPSF', 'IxyPSF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data selecting only point sources\n",
    "data = catalog.get_quantities(['ra', 'dec', 'mag_i', 'i_SNR', 'psf_fwhm_i',\n",
    "                               'g1', 'g2', 'sigma',\n",
    "                               'psf_g1', 'psf_g2', 'psf_sigma'], \n",
    "                               # native_filters=[(lambda x: x==4850, 'tract')],\n",
    "                                filters=[GCRQuery('good'), \n",
    "                                         GCRQuery('clean'), \n",
    "                                        ~GCRQuery('I_flag'),\n",
    "                                        ~GCRQuery('base_SdssShape_flag_badCentroid'),\n",
    "                                         GCRQuery('extendedness == 0'),\n",
    "                                        ~GCRQuery((np.isnan, 'mag_i_cModel')), # (from this and below) remove nan entries\n",
    "                                        ~GCRQuery((np.isnan, 'ext_shapeHSM_HsmShapeRegauss_resolution')),\n",
    "                                        ~GCRQuery((np.isnan, 'ext_shapeHSM_HsmShapeRegauss_e1')),\n",
    "                                        ~GCRQuery((np.isnan, 'ext_shapeHSM_HsmShapeRegauss_e2')),\n",
    "                                         GCRQuery('blendedness < 10**(-0.375)'),\n",
    "                                         GCRQuery('mag_i < 21')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,5))\n",
    "\n",
    "subplot(121)\n",
    "hist2d(data['mag_i'], (data['sigma'] - data['psf_sigma'])/data['psf_sigma'], 100, range=[[15,23],[-0.02,0.02]]);\n",
    "xlabel('i mag')\n",
    "ylabel('$f \\delta_\\sigma$')\n",
    "subplot(122)\n",
    "hist2d(data['psf_fwhm_i'], (data['sigma'] - data['psf_sigma'])/data['psf_sigma'], 100, range=[[0.4,1.0],[-0.02,0.02]]);\n",
    "xlabel('seeing FWHM (arcsec)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(15,10))\n",
    "\n",
    "subplot(221)\n",
    "hist2d(data['mag_i'], (data['g1'] - data['psf_g1']), 100, range=[[15,23],[-0.02,0.02]]);\n",
    "xlabel('i mag')\n",
    "ylabel('$g_1 - g_1^{PSF}$')\n",
    "subplot(222)\n",
    "hist2d(data['psf_fwhm_i'], (data['g1'] - data['psf_g1']), 100, range=[[0.4,1.0],[-0.02,0.02]]);\n",
    "xlabel('seeing FWHM (arcsec)')\n",
    "ylabel('$g_1 - g_1^{PSF}$')\n",
    "\n",
    "subplot(223)\n",
    "hist((data['g1'] - data['psf_g1']), 100, range=[-0.04,0.04]);\n",
    "xlabel('$g_1 - g_1^{PSF}$')\n",
    "axvline(0)\n",
    "subplot(224)\n",
    "hist((data['g2'] - data['psf_g2']), 100, range=[-0.04,0.04]);\n",
    "xlabel('$g_2 - g_2^{PSF}$')\n",
    "axvline(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import stile\n",
    "\n",
    "d = pandas.DataFrame(data)\n",
    "d['w'] =1\n",
    "d = d.to_records(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stile_args = {'ra_units': 'degrees', 'dec_units': 'degrees',\n",
    "              'min_sep': 0.05, 'max_sep': 1, 'sep_units': 'degrees', 'nbins': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho1 = stile.CorrelationFunctionSysTest('Rho1')\n",
    "rho2 = stile.CorrelationFunctionSysTest('Rho2')\n",
    "\n",
    "r1 = rho1(d, config=stile_args)\n",
    "r2 = rho2(d, config=stile_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = rho1.plot(r1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = rho2.plot(r2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-stack",
   "language": "python",
   "name": "desc-stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
